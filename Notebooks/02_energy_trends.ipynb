{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f55dff8-adec-42f8-9264-43a87dd98efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Loading January, February, March & April meter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2b24a8f-ee0d-4ef9-872f-b6a235b4d388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1) Load Jan/Feb/Mar/Apr CSVs\n",
    "jan_path = \"/Volumes/workspace/default/osu-energy-analysis/DATA I-O 2026 Advanced Datasets/advanced_core/advanced_core/meter-readings-jan-2025.csv\"\n",
    "feb_path = \"/Volumes/workspace/default/osu-energy-analysis/DATA I-O 2026 Advanced Datasets/advanced_core/advanced_core/meter-readings-feb-2025.csv\"\n",
    "mar_path = \"/Volumes/workspace/default/osu-energy-analysis/DATA I-O 2026 Advanced Datasets/advanced_core/advanced_core/meter-readings-march-2025.csv\"\n",
    "apr_path = \"/Volumes/workspace/default/osu-energy-analysis/DATA I-O 2026 Advanced Datasets/advanced_core/advanced_core/meter-readings-april-2025.csv\"\n",
    "\n",
    "def load_csv(path):\n",
    "    return (spark.read\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .csv(path))\n",
    "\n",
    "jan = load_csv(jan_path)\n",
    "feb = load_csv(feb_path)\n",
    "mar = load_csv(mar_path)\n",
    "apr = load_csv(apr_path)\n",
    "\n",
    "print(\"JAN:\", jan.count(), \"rows\")\n",
    "print(\"FEB:\", feb.count(), \"rows\")\n",
    "print(\"MAR:\", mar.count(), \"rows\")\n",
    "print(\"APR:\", apr.count(), \"rows\")\n",
    "\n",
    "# 2) Combine ALL months\n",
    "\n",
    "meters = (\n",
    "    jan.unionByName(feb, allowMissingColumns=True)\n",
    "       .unionByName(mar, allowMissingColumns=True)\n",
    "       .unionByName(apr, allowMissingColumns=True)\n",
    ")\n",
    "\n",
    "print(\"TOTAL BEFORE CLEAN:\", meters.count())\n",
    "\n",
    "# 3) Remove nulls in key columns\n",
    "key_cols = [\"readingtime\", \"readingvalue\", \"sitename\", \"utility\"]\n",
    "\n",
    "# (Optional) verify columns exist\n",
    "missing = [c for c in key_cols if c not in meters.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in data: {missing}. Available columns: {meters.columns}\")\n",
    "\n",
    "meters_clean = meters.na.drop(subset=key_cols)\n",
    "\n",
    "print(\"TOTAL AFTER CLEAN:\", meters_clean.count())\n",
    "for c in key_cols:\n",
    "    nulls = meters_clean.filter(col(c).isNull()).count()\n",
    "    print(f\"Nulls remaining in {c}: {nulls}\")\n",
    "\n",
    "# 4) Create schema + Save as Delta Table (THIS CREATES THE TABLE)\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "(meters_clean.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"osu_energy.meters_clean\"))\n",
    "\n",
    "print(\" Saved Delta table: osu_energy.meters_clean\")\n",
    "\n",
    "# 5) Preview saved table\n",
    "display(spark.table(\"osu_energy.meters_clean\").limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cea3d9d-9c1c-45a8-9fd0-97518e23fa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Combine months (temporary for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "933fda80-2259-4c70-b2eb-d7e4693ed41d",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770487392281}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770487451000}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# A) Drop nulls in key columns\n",
    "key_cols = [\"readingtime\", \"readingvalue\", \"sitename\", \"utility\"]\n",
    "\n",
    "missing = [c for c in key_cols if c not in meters.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in data: {missing}. Available columns: {meters.columns}\")\n",
    "\n",
    "meters_clean = meters.na.drop(subset=key_cols)\n",
    "\n",
    "print(\"TOTAL BEFORE CLEAN:\", meters.count())\n",
    "print(\"TOTAL AFTER  CLEAN:\", meters_clean.count())\n",
    "\n",
    "# Optional sanity check (should be 0)\n",
    "for c in key_cols:\n",
    "    print(f\"Nulls remaining in {c}:\", meters_clean.filter(col(c).isNull()).count())\n",
    "\n",
    "display(meters_clean.limit(10))\n",
    "\n",
    "# B) Save as Delta table (creates table)\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "(meters_clean.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"osu_energy.meters_clean\"))\n",
    "\n",
    "print(\"Saved Delta table: osu_energy.meters_clean\")\n",
    "\n",
    "# confirm it saved\n",
    "display(spark.table(\"osu_energy.meters_clean\").limit(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82757c24-8a79-499b-aa58-fe1afbb28019",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Detect the timestamp & usage columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1b57207-aaf1-4825-ab7d-b082462d5bda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# 0) Make sure DB exists\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "\n",
    "# 1) Drop old tables (prevents schema mismatch)\n",
    "spark.sql(\"DROP TABLE IF EXISTS osu_energy.meters_clean\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS osu_energy.daily_trend\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS osu_energy.monthly_trend\")\n",
    "\n",
    "\n",
    "# 2) Save BASE cleaned meter data (raw-level table)\n",
    "(meters_clean.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .saveAsTable(\"osu_energy.meters_clean\"))\n",
    "\n",
    "\n",
    "# 3) Build trends (make sure these match your column names)\n",
    "#    meters_clean should already have: readingtime, readingvalue, sitename, utility\n",
    "\n",
    "df = meters_clean.withColumn(\"ts\", F.to_timestamp(\"readingtime\")) \\\n",
    "                 .withColumn(\"usage\", F.col(\"readingvalue\").cast(\"double\"))\n",
    "\n",
    "daily_trend = (df\n",
    "    .withColumn(\"day\", F.date_trunc(\"day\", F.col(\"ts\")))\n",
    "    .groupBy(\"day\", \"sitename\", \"utility\")\n",
    "    .agg(\n",
    "        F.sum(\"usage\").alias(\"total_usage\"),\n",
    "        F.count(\"*\").alias(\"n_readings\")\n",
    "    )\n",
    ")\n",
    "\n",
    "monthly_trend = (df\n",
    "    .withColumn(\"month\", F.date_trunc(\"month\", F.col(\"ts\")))\n",
    "    .groupBy(\"month\", \"sitename\", \"utility\")\n",
    "    .agg(\n",
    "        F.sum(\"usage\").alias(\"total_usage\"),\n",
    "        F.count(\"*\").alias(\"n_readings\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# 4) Save trends as separate Delta tables\n",
    "\n",
    "(daily_trend.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .saveAsTable(\"osu_energy.daily_trend\"))\n",
    "\n",
    "(monthly_trend.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .saveAsTable(\"osu_energy.monthly_trend\"))\n",
    "\n",
    "print(\"Saved Delta tables:\")\n",
    "print(\" - osu_energy.meters_clean\")\n",
    "print(\" - osu_energy.daily_trend\")\n",
    "print(\" - osu_energy.monthly_trend\")\n",
    "\n",
    "# 5) Quick verify\n",
    "spark.sql(\"SHOW TABLES IN osu_energy\").show(truncate=False)\n",
    "\n",
    "display(spark.table(\"osu_energy.meters_clean\").limit(10))\n",
    "display(spark.table(\"osu_energy.daily_trend\").orderBy(F.col(\"day\").desc()).limit(10))\n",
    "display(spark.table(\"osu_energy.monthly_trend\").orderBy(F.col(\"month\").desc()).limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a53a5fb-c273-4b78-9836-e9fcfa49e248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create month/day/hour fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a51564-a2c7-43e3-9a74-1050ed683183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, dayofmonth, hour\n",
    "\n",
    "df = (df\n",
    "      .withColumn(\"month\", month(col(\"ts\")))\n",
    "      .withColumn(\"day\", dayofmonth(col(\"ts\")))\n",
    "      .withColumn(\"hour\", hour(col(\"ts\"))))\n",
    "\n",
    "display(df.select(\"ts\",\"month\",\"day\",\"hour\",energy_col).limit(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e11cbf-5782-4dd1-82ab-6a30d928d309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Campus-wide monthly trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a24cb86-4414-4f7c-9d7e-d450b900e0d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save monthly trend as Delta table\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "(monthly_trend.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"osu_energy.monthly_trend\"))\n",
    "\n",
    "print(\"Saved table: osu_energy.monthly_trend\")\n",
    "\n",
    "# Preview saved table\n",
    "display(spark.table(\"osu_energy.monthly_trend\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b044148-b7fd-426d-954d-68b9a95f0766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Campus-wide hourly trend (peak hour insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6d0a1ec-2917-47d0-af0e-cbc3d03e6b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save hourly trend as Delta table\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "(hourly_trend.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"osu_energy.hourly_trend\"))\n",
    "\n",
    "print(\"Saved table: osu_energy.hourly_trend\")\n",
    "\n",
    "# Preview saved table\n",
    "display(spark.table(\"osu_energy.hourly_trend\").orderBy(\"hour\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3b22193-ae6f-4ed3-80b1-d685012479f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Daily trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b0f381-eb68-406d-afda-0954485ea9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save daily_trend as Delta table\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS osu_energy\")\n",
    "\n",
    "(daily_trend.write\n",
    "  .mode(\"overwrite\")\n",
    "  .format(\"delta\")\n",
    "  .saveAsTable(\"osu_energy.daily_trend\"))\n",
    "\n",
    "print(\"Saved table: osu_energy.daily_trend\")\n",
    "\n",
    "# Preview saved table (use the REAL columns in your table)\n",
    "display(\n",
    "  spark.table(\"osu_energy.daily_trend\")\n",
    "       .orderBy(\"day\", \"utility\", \"sitename\")\n",
    "       .limit(200)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "829d36c9-01aa-4cb0-8660-7fcd98c5a7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Identify spikes (top 20 highest readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777060a1-0dfc-4b1e-95ba-069090c701f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Force correct energy column\n",
    "energy_col = \"readingvalue\"\n",
    "\n",
    "spikes = (\n",
    "    df.select(\n",
    "        \"ts\",\n",
    "        col(energy_col).cast(\"double\").alias(\"energy_value\")\n",
    "    )\n",
    "    .orderBy(col(\"energy_value\").desc())\n",
    ")\n",
    "\n",
    "display(spikes.limit(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a95e486-9653-4e9d-be55-2d0fec80ff4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_energy_trends",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
